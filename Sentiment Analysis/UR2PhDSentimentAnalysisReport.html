<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=XGMkxXUZTA64h2imyzu79g);.lst-kix_o7eqhcqr0a0-8>li{counter-increment:lst-ctn-kix_o7eqhcqr0a0-8}.lst-kix_o7eqhcqr0a0-5>li{counter-increment:lst-ctn-kix_o7eqhcqr0a0-5}.lst-kix_o7eqhcqr0a0-2>li{counter-increment:lst-ctn-kix_o7eqhcqr0a0-2}ol.lst-kix_o7eqhcqr0a0-7{list-style-type:none}ol.lst-kix_o7eqhcqr0a0-6{list-style-type:none}ol.lst-kix_o7eqhcqr0a0-5{list-style-type:none}ol.lst-kix_o7eqhcqr0a0-4{list-style-type:none}ol.lst-kix_o7eqhcqr0a0-4.start{counter-reset:lst-ctn-kix_o7eqhcqr0a0-4 0}ol.lst-kix_o7eqhcqr0a0-8{list-style-type:none}ol.lst-kix_o7eqhcqr0a0-0.start{counter-reset:lst-ctn-kix_o7eqhcqr0a0-0 0}.lst-kix_o7eqhcqr0a0-0>li{counter-increment:lst-ctn-kix_o7eqhcqr0a0-0}.lst-kix_o7eqhcqr0a0-6>li:before{content:"" counter(lst-ctn-kix_o7eqhcqr0a0-6,decimal) ". "}ol.lst-kix_o7eqhcqr0a0-5.start{counter-reset:lst-ctn-kix_o7eqhcqr0a0-5 0}.lst-kix_o7eqhcqr0a0-5>li:before{content:"" counter(lst-ctn-kix_o7eqhcqr0a0-5,lower-roman) ". "}.lst-kix_o7eqhcqr0a0-4>li{counter-increment:lst-ctn-kix_o7eqhcqr0a0-4}.lst-kix_o7eqhcqr0a0-1>li{counter-increment:lst-ctn-kix_o7eqhcqr0a0-1}ol.lst-kix_o7eqhcqr0a0-7.start{counter-reset:lst-ctn-kix_o7eqhcqr0a0-7 0}.lst-kix_o7eqhcqr0a0-7>li{counter-increment:lst-ctn-kix_o7eqhcqr0a0-7}.lst-kix_o7eqhcqr0a0-2>li:before{content:"" counter(lst-ctn-kix_o7eqhcqr0a0-2,lower-roman) ". "}.lst-kix_o7eqhcqr0a0-4>li:before{content:"" counter(lst-ctn-kix_o7eqhcqr0a0-4,lower-latin) ". "}ol.lst-kix_o7eqhcqr0a0-2.start{counter-reset:lst-ctn-kix_o7eqhcqr0a0-2 0}.lst-kix_o7eqhcqr0a0-3>li:before{content:"" counter(lst-ctn-kix_o7eqhcqr0a0-3,decimal) ". "}.lst-kix_o7eqhcqr0a0-0>li:before{content:"" counter(lst-ctn-kix_o7eqhcqr0a0-0,decimal) ". "}.lst-kix_o7eqhcqr0a0-1>li:before{content:"" counter(lst-ctn-kix_o7eqhcqr0a0-1,lower-latin) ". "}ol.lst-kix_o7eqhcqr0a0-3.start{counter-reset:lst-ctn-kix_o7eqhcqr0a0-3 0}ol.lst-kix_o7eqhcqr0a0-8.start{counter-reset:lst-ctn-kix_o7eqhcqr0a0-8 0}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_o7eqhcqr0a0-7>li:before{content:"" counter(lst-ctn-kix_o7eqhcqr0a0-7,lower-latin) ". "}ol.lst-kix_o7eqhcqr0a0-6.start{counter-reset:lst-ctn-kix_o7eqhcqr0a0-6 0}.lst-kix_o7eqhcqr0a0-3>li{counter-increment:lst-ctn-kix_o7eqhcqr0a0-3}.lst-kix_o7eqhcqr0a0-8>li:before{content:"" counter(lst-ctn-kix_o7eqhcqr0a0-8,lower-roman) ". "}ol.lst-kix_o7eqhcqr0a0-3{list-style-type:none}.lst-kix_o7eqhcqr0a0-6>li{counter-increment:lst-ctn-kix_o7eqhcqr0a0-6}ol.lst-kix_o7eqhcqr0a0-2{list-style-type:none}ol.lst-kix_o7eqhcqr0a0-1{list-style-type:none}ol.lst-kix_o7eqhcqr0a0-0{list-style-type:none}ol.lst-kix_o7eqhcqr0a0-1.start{counter-reset:lst-ctn-kix_o7eqhcqr0a0-1 0}ol{margin:0;padding:0}table td,table th{padding:0}.c8{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:468pt;border-top-color:#000000;border-bottom-style:solid}.c10{margin-left:36pt;padding-top:14pt;padding-left:0pt;padding-bottom:14pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c16{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:13pt;font-family:"Arial";font-style:normal}.c4{color:#188038;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Roboto Mono";font-style:normal}.c3{padding-top:14pt;padding-bottom:14pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c9{color:#666666;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c6{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c17{padding-top:14pt;padding-bottom:4pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c7{padding-top:12pt;padding-bottom:2pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c12{padding-top:14pt;padding-bottom:14pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c0{border-spacing:0;border-collapse:collapse;margin-right:auto}.c15{background-color:#ffffff;max-width:468pt;padding:45pt 72pt 72pt 72pt}.c18{color:#000000;font-size:11pt;font-weight:700}.c13{color:#188038;font-weight:400;font-family:"Roboto Mono"}.c14{padding:0;margin:0}.c11{height:0pt}.c5{height:11pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c15 doc-content"><h3 class="c17" id="h.2tnbcep3n7y1"><span class="c16">Building a Sentiment Analysis using IMDB Movie Reviews</span></h3><h4 class="c7" id="h.chjo19cg079s"><span class="c6">Introduction</span></h4><p class="c12"><span class="c2">Creating a vocabulary index is crucial in Natural Language Processing (NLP) for analyzing text data. This article outlines a method to generate such an index using the IMDB movie reviews dataset for sentiment analysis, focusing on data loading, text preprocessing, and vocabulary creation.</span></p><p class="c3"><span class="c2"></span></p><h4 class="c7" id="h.q8tgyxhwr024"><span class="c18">Loading the Dataset</span></h4><p class="c12"><span>We begin by loading the IMDB dataset using the Pandas library. After installing the dataset from Kaggle and checking the format, we know that the file is named </span><span class="c13">IMDB_Dataset.csv</span><span>, with a column labelled </span><span class="c13">review</span><span class="c2">.</span></p><table class="c0"><tr class="c11"><td class="c8" colspan="1" rowspan="1"><p class="c1"><span class="c13">df = pd.read_csv(&#39;IMDB_Dataset.csv&#39;) &nbsp;# Load the IMDB dataset</span></p></td></tr></table><p class="c1 c5"><span class="c2"></span></p><p class="c1 c5"><span class="c2"></span></p><h4 class="c7" id="h.4z1sw88grbat"><span class="c6">Preprocessing the Text</span></h4><p class="c12"><span class="c2">Next, we preprocess the reviews to standardize the text. This process involves:</span></p><ol class="c14 lst-kix_o7eqhcqr0a0-0 start" start="1"><li class="c10 li-bullet-0"><span class="c2">Converting text to lowercase.</span></li><li class="c10 li-bullet-0"><span class="c2">Removing punctuation.</span></li><li class="c10 li-bullet-0"><span class="c2">Tokenizing the text into individual words.</span></li></ol><p class="c12"><span>The preprocessing function is defined as follows:</span></p><table class="c0"><tr class="c11"><td class="c8" colspan="1" rowspan="1"><p class="c1"><span class="c4">def preprocess_text(text):</span></p><p class="c1"><span class="c4">&nbsp; &nbsp; text = text.lower() &nbsp;# Convert to lowercase</span></p><p class="c1"><span class="c4">&nbsp; &nbsp; text = text.translate(str.maketrans(&#39;&#39;, &#39;&#39;, string.punctuation)) &nbsp;# Remove punctuation</span></p><p class="c1"><span class="c4">&nbsp; &nbsp; return text.split() &nbsp;# Tokenize into words</span></p></td></tr></table><p class="c1 c5"><span class="c2"></span></p><p class="c1 c5"><span class="c2"></span></p><h4 class="c7" id="h.mfs641bzzxok"><span class="c6">Combining Reviews into a Single List</span></h4><p class="c12"><span class="c2">We combine all processed reviews into a single list of words using the following code:</span></p><p class="c1 c5"><span class="c4"></span></p><table class="c0"><tr class="c11"><td class="c8" colspan="1" rowspan="1"><p class="c1"><span class="c4">all_words = []</span></p><p class="c1"><span class="c4">for review in df[&#39;review&#39;]: &nbsp;# Assuming the reviews are in a column named &#39;review&#39;</span></p><p class="c1"><span class="c4">&nbsp; &nbsp; all_words.extend(preprocess_text(review))</span></p></td></tr></table><p class="c1 c5"><span class="c4"></span></p><p class="c1 c5"><span class="c4"></span></p><h4 class="c7" id="h.574w1x30ve2z"><span class="c6">Creating a Vocabulary</span></h4><p class="c12"><span>Using the </span><span class="c13">Counter</span><span class="c2">&nbsp;class, we count the occurrences of each word and create a mapping from each word to a unique index:</span></p><p class="c1 c5"><span class="c4"></span></p><table class="c0"><tr class="c11"><td class="c8" colspan="1" rowspan="1"><p class="c1"><span class="c4">word_counts = Counter(all_words) &nbsp;# Count occurrences of each word</span></p><p class="c1"><span class="c4">word_to_index = {word: idx + 1 for idx, (word, _) in enumerate(word_counts.items())} &nbsp;# Create mapping</span></p></td></tr></table><p class="c1 c5"><span class="c4"></span></p><p class="c12"><span class="c2">We reserve index 0 for padding purposes.</span></p><p class="c3"><span class="c2"></span></p><h4 class="c7" id="h.djxrk6yzyjfp"><span class="c6">Saving the Vocabulary Index</span></h4><p class="c12"><span>Finally, we save the vocabulary index to a CSV file for easy access:</span></p><table class="c0"><tr class="c11"><td class="c8" colspan="1" rowspan="1"><p class="c1"><span class="c4">word_index_df = pd.DataFrame(list(word_to_index.items()), columns=[&#39;Word&#39;, &#39;Index&#39;]) &nbsp;# Convert to DataFrame</span></p><p class="c1"><span class="c4">word_index_df.to_csv(&#39;word_index.csv&#39;, index=False) &nbsp;# Save to CSV</span></p></td></tr></table><p class="c1 c5"><span class="c4"></span></p><h4 class="c7" id="h.8o5ut0xwlmxk"><span class="c18">Conclusion</span></h4><p class="c12"><span>This process demonstrates the creation of a vocabulary index from the IMDB movie reviews dataset. The resulting </span><span class="c13">word_index.csv</span><span class="c2">&nbsp;file is essential for effective text representation in NLP tasks. This methodology can be applied to various datasets, providing a solid foundation for further text analysis and machine learning exploration.</span></p></body></html>